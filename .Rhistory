geom_histogram(color='white', fill='blue') +
theme_minimal()
house_df[[var]] <- transformInv(house_df[[var]])
house_df_test[[var]] <- transformInv(house_df_test[[var]])
house_df_comp[[var]] <- transformInv(house_df_comp[[var]])
ggplot(house_df, aes(x = pop_per_household)) +
geom_histogram(color='white', fill='blue') +
theme_minimal()
qqPlot(house_df[[var]])
var <- "bedrooms_pop_ratio"
summary(house_df[[var]])
qqPlot(house_df[[var]])
ggplot(house_df, aes(x = bedrooms_pop_ratio)) +
geom_histogram(color='white', fill='blue') +
theme_minimal()
house_df[[var]] <- transformInv(house_df[[var]])
house_df_test[[var]] <- transformInv(house_df_test[[var]])
house_df_comp[[var]] <- transformInv(house_df_comp[[var]])
ggplot(house_df, aes(x = bedrooms_pop_ratio)) +
geom_histogram(color='white', fill='blue') +
theme_minimal()
qqPlot(house_df[[var]])
house_df %>%
ggplot() +
geom_density(aes(housing_median_age)) +
geom_density(aes(total_rooms)) +
geom_density(aes(total_bedrooms)) +
geom_density(aes(population)) +
geom_density(aes(households)) +
geom_density(aes(median_income))
cols <- colnames(house_df %>% select(-contains('.'), -c("median_house_value")))
house_df_scaled <- cbind(house_df %>% select(cols) %>% normalize(), house_df %>% select(contains('.'), median_house_value))
house_df_test_scaled <- cbind(house_df_test %>% select(cols) %>% normalize(), house_df_test %>% select(contains('.'), median_house_value))
house_df_comp_scaled <- cbind(house_df_comp %>% select(cols) %>% normalize(), house_df_comp %>% select(contains('.')))
house_df_scaled %>%
ggplot() +
geom_density(aes(housing_median_age), color="red") +
geom_density(aes(total_rooms)) +
geom_density(aes(total_bedrooms)) +
geom_density(aes(population)) +
geom_density(aes(households)) +
geom_density(aes(median_income))
#
# bedrooms_rooms_ratio = total_bedrooms / total_rooms,
#      bedrooms_per_household = total_bedrooms / households,
#      rooms_per_household = total_rooms / households,
#      pop_per_household = population / households,
#      bedrooms_pop_ratio = total_bedrooms / population,
#      extra_rooms_ratio = (total_rooms - total_bedrooms)/population
house_df <- house_df %>% select(-c("total_rooms", "total_bedrooms", "extra_rooms_ratio", "bedrooms_pop_ratio", "pop_per_household"))
house_df_scaled <- house_df_scaled %>% select(-c("total_rooms", "total_bedrooms", "extra_rooms_ratio", "bedrooms_pop_ratio", "pop_per_household"))
house_df_test <- house_df_test %>% select(-c("total_rooms", "total_bedrooms", "extra_rooms_ratio", "bedrooms_pop_ratio", "pop_per_household"))
house_df_test_scaled <- house_df_test_scaled %>% select(-c("total_rooms", "total_bedrooms", "extra_rooms_ratio", "bedrooms_pop_ratio", "pop_per_household"))
data <- house_df_scaled %>% select(-c("longitude", "latitude"))
lin_reg <- modelSelector(data, which(colnames(data) == "median_house_value"))
summary(lin_reg)
pred_test <- predict(lin_reg, newdata=house_df_test_scaled)
rmse.lin_reg <- RMSE(pred_test, house_df_test$median_house_value)
rmse.lin_reg
linear <- list(rmse=rmse.lin_reg, name="Linear Model")
customControl<-trainControl(method = "repeatedcv",
number=10,
repeats=5,
verboseIter = F)
model <-train(median_house_value ~ .,
house_df_scaled,
method="glmnet",
tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 100, length=40)),
trControl=customControl)
model$results
plot(model)
model
plot(model$finalModel, xvar="lambda", label = TRUE)
plot(model$finalModel, xvar="dev", label = TRUE)
plot(varImp(model, scale=T))
coef(model$finalModel, s=model$bestTune$lambda)
pred_test <- predict(model, newdata=house_df_test_scaled)
rmse.lin_reg_lasso <- RMSE(pred_test, house_df_test$median_house_value)
rmse.lin_reg_lasso
regul <- list(rmse=rmse.lin_reg_lasso, name="Lasso Regul")
library(randomForest)
rf_model <- randomForest(formula = median_house_value ~ ., data=house_df, ntree=500, importance=TRUE)
pred_test <- predict(rf_model, newdata=house_df_test)
rmse.rf_lasso <- RMSE(pred_test, house_df_test$median_house_value)
rmse.rf_lasso
rf_lasso <- list( rmse=rmse.rf_lasso, name="RF Lasso")
res <- predict(rf_model, newdata=house_df_comp)
results <- data.frame(id=house_df_comp_ids$id,median_house_value = res)
write_csv(results, file = "results-rf-lasso.csv", append = FALSE, col_names = TRUE)
rf_model_2 <- randomForest(formula = median_house_value ~ ., data=house_df_scaled, ntree=500, importance=TRUE)
pred_test <- predict(rf_model_2, newdata=house_df_test_scaled)
rmse.rf_lasso_scaled <- RMSE(pred_test, house_df_test_scaled$median_house_value)
rmse.rf_lasso_scaled
rf_lasso_scaled <- list(rmse=rmse.rf_lasso_scaled, "RF Lasso Scaled")
res <- predict(rf_model_2, newdata=house_df_comp_scaled)
results <- data.frame(id=house_df_comp_ids$id,median_house_value = res)
write_csv(results, file = "results-rf-lasso-scaled.csv", append = FALSE, col_names = TRUE)
library(h2o)
library(bit64)
h2o.no_progress()
h2o.init(max_mem_size = "12g")
y <- "median_house_value"
x <- setdiff(names(house_df), y)
train.h2o <- as.h2o(house_df)
# hyperparameter grid
hyper_grid.h2o <- list(
ntrees      = seq(10, 60, by=10),
mtries      = seq(3,16, by=2),
sample_rate = c(.632, .70)
)
grid <- h2o.grid(
algorithm = "randomForest",
grid_id = "rf_grid",
x = x,
y = y,
training_frame = train.h2o,
hyper_params = hyper_grid.h2o,
search_criteria = list(strategy = "Cartesian")
)
grid_perf <- h2o.getGrid(
grid_id = "rf_grid",
sort_by = "mse",
decreasing = FALSE
)
print(grid_perf)
checkRMSE <- function(model_id, objectives){
model <- h2o.getModel(model_id)
test.h2o <- as.h2o(objectives)
model_perf <- h2o.performance(model = model, newdata = test.h2o)
# RMSE of best model
rmse <- h2o.rmse(model_perf)
print(rmse)
rmse
}
best_model_id <- grid_perf@model_ids[[which.min(sapply(grid_perf@model_ids, function(model_id) checkRMSE(model_id, house_df_test)))]]
best_model_rf <- h2o.getModel(best_model_id)
data_test <- as.h2o(house_df_test)
pred_test <- as.data.frame(predict(best_model_rf, newdata=data_test))
rmse.rf <- RMSE(pred_test$predict, house_df_test$median_house_value)
rmse.rf
rf <- list(rmse=rmse.rf, name="RF")
data_comp <- as.h2o(house_df_comp)
res <- predict(best_model_rf, newdata=data_comp)
res <- as.data.frame(res)
results <- data.frame(id=house_df_comp_ids$id,median_house_value = res$predict)
write_csv(results, file = "results-rf.csv", append = FALSE, col_names = TRUE)
train.h2o <- as.h2o(house_df_scaled)
# hyperparameter grid
hyper_grid.h2o <- list(
ntrees      = seq(10, 60, by=10),
mtries      = seq(3,16, by=2),
sample_rate = c(.632, .70)
)
grid <- h2o.grid(
algorithm = "randomForest",
grid_id = "rf_grid_scaled",
x = x,
y = y,
training_frame = train.h2o,
hyper_params = hyper_grid.h2o,
search_criteria = list(strategy = "Cartesian")
)
grid_perf <- h2o.getGrid(
grid_id = "rf_grid_scaled",
sort_by = "mse",
decreasing = FALSE
)
print(grid_perf)
best_model_id <- grid_perf@model_ids[[which.min(sapply(grid_perf@model_ids, function(model_id) checkRMSE(model_id, house_df_test_scaled)))]]
best_model_rf_scaled <- h2o.getModel(best_model_id)
data_test <- as.h2o(house_df_test_scaled)
pred_test <- as.data.frame(predict(best_model_rf_scaled, newdata=data_test))
rmse.rf_scaled <- RMSE(pred_test$predict, house_df_test_scaled$median_house_value)
rmse.rf_scaled
rf_scaled <- list(rmse=rmse.rf_scaled, name="RF Scaled")
data_comp <- as.h2o(house_df_comp_scaled)
res <- predict(best_model_rf_scaled, newdata=data_comp)
res <- as.data.frame(res)
results <- data.frame(id=house_df_comp_ids$id,median_house_value = res$predict)
write_csv(results, file = "results-rf-scaled.csv", append = FALSE, col_names = TRUE)
# library(xgboost)
# sample = sample.int(n = nrow(house_df), size = floor(.8*nrow(house_df)), replace = F)
#
# train <- house_df[sample,]
# valid <- house_df[-sample,]
#
# train_x <- train %>% select(-c("median_house_value"))
# train_y <- train %>% select("median_house_value")
# valid_x <- valid %>% select(-c("median_house_value"))
# valid_y <- valid %>% select("median_house_value")
# test_x <- house_df_test %>% select(-c("median_house_value"))
# test_y <- house_df_test %>% select("median_house_value")
#
# dtrain <- xgb.DMatrix(data =  as.matrix(train_x), label = as.matrix(train_y))
# dvalid <- xgb.DMatrix(data =  as.matrix(valid_x), label = as.matrix(valid_y))
# dtest <- xgb.DMatrix(data =  as.matrix(test_x), label = as.matrix(test_y))
# watchlist <- list(train=dtrain, test=dvalid)
#
#
# max.depths <- c(7, 9)
# etas <- c(0.01, 0.001)
#
# best_params <- 0
# best_score <- 0
#
# count <- 1
# for( depth in max.depths ){
#     for( num in etas){
#
#         bst_grid <- xgb.train(data = dtrain,
#                                 max.depth = depth,
#                                 eta=num,
#                                 nthread = 2,
#                                 nround = 10000,
#                                 watchlist = watchlist,
#                                 objective = "reg:squarederror",
#                                 early_stopping_rounds = 50,
#                                 verbose=0)
#
#         if(count == 1){
#             best_params <- bst_grid$params
#             best_score <- bst_grid$best_score
#             count <- count + 1
#             }
#         else if( bst_grid$best_score < best_score){
#             best_params <- bst_grid$params
#             best_score <- bst_grid$best_score
#         }
#     }
# }
#
# best_params
# best_score
# gbm_tuned <- xgb.train(data = dtrain,
#                                 max.depth = best_params$max_depth,
#                                 eta=best_params$eta,
#                                 nthread = best_params$nthread,
#                                 nround = 10000,
#                                 watchlist = watchlist,
#                                 objective = "reg:squarederror",
#                                 early_stopping_rounds = 100,
#                                 verbose=0)
#
#
# pred_test <- predict(gbm_tuned, newdata=dtest)
# rmse.xgb <- RMSE(pred_test, house_df_test$median_house_value)
# rmse.xgb
# xgb <- list(rmse=rmse.xgb, name="XGB")
#
# cols <- colnames(house_df %>% select(-c("median_house_value")))
#
# dcomp = xgb.DMatrix(data =  as.matrix(house_df_comp %>% select(cols)))
# res <- predict(gbm_tuned, newdata=dcomp)
#
# write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = res), file = "results-gbm.csv", append = FALSE, col_names = TRUE)
# train <- house_df_scaled[sample,]
# valid <- house_df_scaled[-sample,]
# train_x <- train %>% select(-c("median_house_value"))
# train_y <- train %>% select("median_house_value")
# valid_x <- valid %>% select(-c("median_house_value"))
# valid_y <- valid %>% select("median_house_value")
# test_x <- house_df_test_scaled %>% select(-c("median_house_value"))
# test_y <- house_df_test_scaled %>% select("median_house_value")
#
# dtrain <- xgb.DMatrix(data =  as.matrix(train_x), label = as.matrix(train_y))
# dvalid <- xgb.DMatrix(data =  as.matrix(valid_x), label = as.matrix(valid_y))
# dtest <- xgb.DMatrix(data =  as.matrix(test_x), label = as.matrix(test_y))
# watchlist <- list(train=dtrain, test=dvalid)
#
#
# max.depths <- c(7, 9)
# etas <- c(0.01, 0.001)
#
# best_params <- 0
# best_score <- 0
#
# count <- 1
# for( depth in max.depths ){
#     for( num in etas){
#
#         bst_grid <- xgb.train(data = dtrain,
#                                 max.depth = depth,
#                                 eta=num,
#                                 nthread = 2,
#                                 nround = 10000,
#                                 watchlist = watchlist,
#                                 objective = "reg:squarederror",
#                                 early_stopping_rounds = 50,
#                                 verbose=0)
#
#         if(count == 1){
#             best_params <- bst_grid$params
#             best_score <- bst_grid$best_score
#             count <- count + 1
#             }
#         else if( bst_grid$best_score < best_score){
#             best_params <- bst_grid$params
#             best_score <- bst_grid$best_score
#         }
#     }
# }
#
# best_params
# best_score
# gbm_tuned <- xgb.train(data = dtrain,
#                                 max.depth = best_params$max_depth,
#                                 eta=best_params$eta,
#                                 nthread = best_params$nthread,
#                                 nround = 10000,
#                                 watchlist = watchlist,
#                                 objective = "reg:squarederror",
#                                 early_stopping_rounds = 50,
#                                 verbose=0)
#
# cols <- colnames(house_df %>% select(-c("median_house_value")))
#
# pred_test <- predict(gbm_tuned, newdata=dtest)
# rmse.xgb_scaled <- RMSE(pred_test, house_df_test$median_house_value)
# rmse.xgb_scaled
# xgb_scaled <- list(rmse=rmse.xgb_scaled, name="XGB Scaled")
#
# dcomp = xgb.DMatrix(data =  as.matrix(house_df_comp_scaled %>% select(gbm_tuned$feature_names)))
# res <- predict(gbm_tuned, newdata=dcomp)
# write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = res), file = "results-gbm-scaled.csv", append = FALSE, col_names = TRUE)
train_x <- house_df_scaled %>% select(-c("median_house_value"))
train_y <- house_df_scaled[,'median_house_value']
test_x <- house_df_test_scaled %>% select(-c("median_house_value"))
test_y <- house_df_test_scaled[,'median_house_value']
# look up the model we are running to see the paramaters
modelLookup("xgbLinear")
# set up all the pairwise combinations
xgb_grid_1 <- expand.grid(nrounds = c(1000,2000) ,
eta = c(0.01, 0.001, 0.0001),
lambda = seq(0.0001, 100, length=10),
alpha = 0)
xgb_grid_1
#here we do one better then a validation set, we use cross validation to
#expand the amount of info we have!
xgb_trcontrol_1 <- trainControl(method = "cv",
number = 5,
verboseIter = TRUE,
returnData = FALSE,
returnResamp = "all",
allowParallel = TRUE)
xgb_train_cv <- train(x = as.matrix(train_x),
y = train_y,
trControl = xgb_trcontrol_1,
tuneGrid = xgb_grid_1,
method = "xgbLinear",
max.depth = 5)
names(xgb_train_cv)
xgb_train_cv$bestTune
xgb_train_cv$method
summary(xgb_train_cv)
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(test_x))
test_rmse <- RMSE(xgb_cv_pred, test_y)
test_rmse
xgb_cv_scaled <- list(rmse=test_rmse, name="XGB CV Scaled")
x <- as.matrix(house_df_comp_scaled)
res <- predict(xgb_train_cv, newdata=x)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = res), file = "results-xgb-cv.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_1 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
result <- 0.5 * xgb_cv_pred + 0.5 * res$predict
return(result)
}
rmse.ensemble_xgb_rf <- RMSE(predict_ensemble_1(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_1 <- list(rmse=rmse.ensemble_xgb_rf, name="Ensemble Scaled")
result <- predict_ensemble_1(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble.csv", append = FALSE, col_names = TRUE)
library(e1071)
svm_tunning <- tune(svm, median_house_value ~ median_income + households + population + latitude + longitude + ocean_proximity.INLAND + bedrooms_rooms_ratio + housing_median_age + rooms_per_household + ocean_proximity.NEAR.BAY, data=house_df_scaled,ranges=list(elsilon=seq(0,1,0.1), cost=5))
model_svm <- svm_tunning$best.model
rmse.svm <- RMSE(predict(model_svm, newdata=house_df_test_scaled), house_df_test_scaled$median_house_value)
svm_scaled <- list(rmse=rmse.svm, name="SVM Scaled")
result <- predict(model_svm, newdata=house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-svm.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
result <- 0.4 * xgb_cv_pred + 0.4 * res$predict + 0.2 * svm_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
result <- 0.4 * xgb_cv_pred + 0.3 * res$predict + 0.3 * svm_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
auto_ml@leaderboard %>%
as.data.frame() %>%
dplyr::select(model_id, rmse) %>%
dplyr::slice(1:25)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
result <- 0.5 * xgb_cv_pred + 0.25 * res$predict + 0.25 * svm_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
result <- 0.4 * xgb_cv_pred + 0.4 * res$predict + 0.2 * svm_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
result <- 0.3 * xgb_cv_pred + 0.5 * res$predict + 0.2 * svm_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
lasso_pred = predict(model, newdata=house_df_test_scaled)
result <- 0.25 * xgb_cv_pred + 0.25 * res$predict + 0.25 * svm_pred + 0.25 * lasso_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
# xgb cv scaled, rf scaled
predict_ensemble_2 <- function(newdata){
data_comp <- as.h2o(newdata)
res <- as.data.frame(predict(best_model_rf_scaled, newdata=data_comp))
xgb_cv_pred <- predict(xgb_train_cv , as.matrix(newdata))
svm_pred = predict(model_svm, newdata=newdata)
lasso_pred = predict(model, newdata=newdata)
result <- 0.25 * xgb_cv_pred + 0.25 * res$predict + 0.25 * svm_pred + 0.25 * lasso_pred
return(result)
}
rmse.ensemble_xgb_rf_svm <- RMSE(predict_ensemble_2(house_df_test_scaled), house_df_test_scaled$median_house_value)
ensemble_2 <- list(rmse=rmse.ensemble_xgb_rf_svm, name="Ensemble Scaled")
result <- predict_ensemble_2(house_df_comp_scaled)
write_csv(data.frame(id=house_df_comp_ids$id,median_house_value = result), file = "results-ensemble-2.csv", append = FALSE, col_names = TRUE)
h2o.shutdown()
h2o.shutdown()
h2o.shutdown()
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
str(model)
model
model.weights()
model.residuals
mean(model$residuals ^2)/2
if(!require(installr)) {
install.packages("installr");
require(installr)
} #load / install+load
updateR()
q()
library(reticulate)
use_condaenv("galileo_2021")
shiny::runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
reticulate::repl_python()
with open(path, 'wb') as f:
quit()
quit()
exit()
quit
runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
library(reticulate)
use_condaenv("galileo_2021")
shiny::runApp('C:/Users/mazg9/repos/AlgorithmsDS/Laboratory/plataforma_base/App')
